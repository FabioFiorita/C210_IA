{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Adaline\n",
    "\n",
    "* Adaptive Linear Neuron\n",
    "* 1960 - Widrow e Holf\n",
    "* Alimentação adiante\n",
    "* Minimizar o erro quadrático de todo o conjunto de amostras\n",
    "* Vetor gradiente -> aponta para o crescimento da função\n",
    "\n",
    "<img src=\"images/adaline.png\">\n",
    "\n",
    "<img src=\"images/gradiente.png\">\n",
    "\n",
    "* Regra delta: o ajuste nos pesos deve se dar no sentido contrário do gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "x = np.array([[1.0, 1.0], [2.1, 2.4], [1.1, 0.3], [2.3, 3.2], [0.1, 0.6],\n",
    "              [0.5, 1.6], [1.7, 2.3], [0.7, 1.6], [3.2, 0.1], [2.2, 1.1],\n",
    "              [0.8, 1.9], [2.4, 1.6], [1.2, 1.2], [5.2, 7.2], [6.6, 4.5],\n",
    "              [4.9, 8.1], [7.6, 5.9], [8.8, 9.0], [5.6, 7.8], [8.8, 5.6],\n",
    "              [7.9, 9.1], [6.8, 9.2], [8.8, 6.9], [9.3, 5.6], [5.7, 7.5]\n",
    "             ])\n",
    "\n",
    "d = np.array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "shuffle = np.random.permutation(len(x))\n",
    "x = x[shuffle]\n",
    "d = d[shuffle]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.title(\"Data points\")\n",
    "plt.scatter(x[:, 0], x[:, 1], c = d, cmap = 'bwr')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline:\n",
    "    \n",
    "    def __init__(self, lr, e):\n",
    "        '''Construtor, define taxa de aprendizado e a taxa de erro aceita para convergir'''\n",
    "        self.lr = lr\n",
    "        self.e = e\n",
    "        \n",
    "    def activation(self, value):\n",
    "        ''' 1 se value > 0, -1 senão'''\n",
    "        return (1 if value >= 0 else -1)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        ''' Multiplicação matricial entre as entradas e os pesos somado ao bias proporcional'''\n",
    "        return np.dot(x, self.weights.T) + self.bias * self.w_bias\n",
    "    \n",
    "    def evaluate(self, target, predicted):\n",
    "        ''' Calcula a diferença entre o valor real e o valor predito'''\n",
    "        return (target - predicted)\n",
    "    \n",
    "    def train(self, x, d):\n",
    "        ''' Definir aleatoriamente os pesos, o bias e o peso do bias\n",
    "            Enquanto a diferença entre m mse_anterior e o mse_atual for maior que 'e' continua o processo \n",
    "        '''\n",
    "        self.weights = np.random.random(x.shape[1])\n",
    "        self.bias = -1\n",
    "        self.w_bias = np.random.random()\n",
    "        \n",
    "        epoch = 0\n",
    "        self.total_mse = []\n",
    "        last_mse = np.inf\n",
    "        \n",
    "        \n",
    "        while True:\n",
    "            mse = 0\n",
    "            # Para cada amostra\n",
    "            for xi, target in zip(x, d):\n",
    "                \n",
    "                predicted = self.predict(xi)  \n",
    "                current_error = self.evaluate(target, predicted)\n",
    "                mse += (current_error ** 2)\n",
    "                self.weights += self.lr * current_error * xi\n",
    "                self.w_bias += self.lr * current_error * self.bias\n",
    "                \n",
    "            mse = (mse/len(x))\n",
    "            print(f\"EPOCH: {epoch}\\t- MSE: {mse}\\t- MSE_ant - MSE: {abs(last_mse - mse)}\")\n",
    "            if abs(last_mse - mse) <= self.e:\n",
    "                break\n",
    "            \n",
    "            self.total_mse.append(mse)\n",
    "            last_mse = mse\n",
    "            epoch +=1\n",
    "            \n",
    "    def test(self, x):\n",
    "        ''' Dado uma lista de X, submete-os à rede'''\n",
    "        results = []\n",
    "        for xi in x:\n",
    "            predict = self.predict(xi)\n",
    "            predict = self.activation(predict)\n",
    "            results.append(predict)\n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede = Adaline(lr = 0.01, e = 1e-4)\n",
    "rede.train(x = x, d = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste = np.array([[1, 4], [3, 1], [3, 2], [5, 5], [6, 7], [4, 8]])\n",
    "\n",
    "teste_resultado = rede.test(x_teste)\n",
    "teste_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title(\"Data points + Predicted\")\n",
    "plt.scatter(x[:, 0], x[:, 1], c = d, cmap = 'bwr')\n",
    "plt.scatter(x_teste[:, 0], x_teste[:, 1], c = teste_resultado, cmap = 'bwr', marker = \"*\", s=250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.title(\"Error\")\n",
    "plt.plot(rede.total_mse)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
